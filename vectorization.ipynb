{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac59dd6a-2362-47a2-9f57-978a666114b4",
   "metadata": {},
   "source": [
    "## Import libraries and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1059f0d-f97b-4840-a62f-8040aa783850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import Normalizer, StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "\n",
    "# Define the path to the data file\n",
    "path = '../BDS_project/final_new_data_processed.csv'\n",
    "\n",
    "# Load the data from the CSV file\n",
    "data = pd.read_csv(path)\n",
    "\n",
    "# Drop unnecessary columns from the data and assign the remaining to X\n",
    "X = data.drop(['review', 'rating', 'date', 'review_sentiment'], axis=1)\n",
    "\n",
    "# Assign the 'review_sentiment' column to y\n",
    "y = data['review_sentiment'].values\n",
    "\n",
    "# Split the data into training and testing sets, ensuring stratified sampling and a test size of 30%\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.30, random_state=42)\n",
    "\n",
    "# Further split the training data into training and cross-validation sets, ensuring stratified sampling and a cross-validation size of 30%\n",
    "X_train, X_cv, y_train, y_cv = train_test_split(X_train, y_train, stratify=y_train, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d47eda-bce1-4ad7-8157-f0215df10211",
   "metadata": {},
   "source": [
    "## Get BoW Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733e92cc-c7cc-4817-8ed2-e31fd30d4d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize CountVectorizer with minimum document frequency of 10 and unigram setting\n",
    "vect_bow_1 = CountVectorizer(min_df=10, ngram_range=(1, 1))\n",
    "\n",
    "# Fit the vectorizer on the 'cleaned_review' column of the training data\n",
    "vect_bow_1.fit(X_train['cleaned_review'].values)\n",
    "\n",
    "# Save the fitted vectorizer to a file for future use\n",
    "joblib.dump(vect_bow_1, '../BDS_project/vectorizer_bow.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d08d6e8-74a7-4c9d-8a5a-4e79382cae96",
   "metadata": {},
   "source": [
    "## Get TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7121647-f32a-41ea-a39a-dcb81f5004b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize TfidfVectorizer with minimum document frequency of 10 and unigram setting\n",
    "vect_tfidf_1 = TfidfVectorizer(min_df=10, ngram_range=(1, 1))\n",
    "\n",
    "# Fit the vectorizer on the 'cleaned_review' column of the training data\n",
    "vect_tfidf_1.fit(X_train['cleaned_review'].values)\n",
    "\n",
    "# Save the fitted vectorizer to a file for future use\n",
    "joblib.dump(vect_tfidf_1, '../BDS_project/vectorizer_tfidf.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da4bac0-90cd-4cc2-b120-9ad085cc624f",
   "metadata": {},
   "source": [
    "## Get n-gram + BoW Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9fa250-1d0e-4fe7-b550-91e6e236ed34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize CountVectorizer with minimum document frequency of 10 and n-gram range from 2 to 4\n",
    "ngram_vec_bow = CountVectorizer(min_df=10, ngram_range=(2, 4))\n",
    "\n",
    "# Fit the vectorizer on the 'cleaned_review' column of the training data\n",
    "ngram_vec_bow.fit(X_train['cleaned_review'].values)\n",
    "\n",
    "# Create an empty list to store the vocabulary\n",
    "vocab = []\n",
    "\n",
    "# Loop through the feature names of the vectorizer\n",
    "for i in ngram_vec_bow.get_feature_names_out():\n",
    "    # If the word 'no' is in the feature name, add it to the vocabulary list\n",
    "    if 'no' in i.split(' '):\n",
    "        vocab.append(i)\n",
    "\n",
    "# Initialize a new CountVectorizer with the same n-gram range but with the new vocabulary\n",
    "ngram_vec_bow = CountVectorizer(ngram_range=(2, 4), vocabulary=vocab)\n",
    "\n",
    "# Save the fitted vectorizer to a file for future use\n",
    "joblib.dump(ngram_vec_bow, '../BDS_project/ngram_vec_bow.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669138f2-daca-46d6-a975-3a85685c649e",
   "metadata": {},
   "source": [
    "## Get n-gram + TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350600f3-ce9b-45fc-b2b6-7baac6e848c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize TfidfVectorizer with n-gram range from 2 to 4 and the previously defined vocabulary\n",
    "ngram_vec_tfidf = TfidfVectorizer(ngram_range=(2, 4), vocabulary=vocab)\n",
    "\n",
    "# Fit the vectorizer on the vocabulary\n",
    "ngram_vec_tfidf.fit(vocab)\n",
    "\n",
    "# Save the fitted vectorizer to a file for future use\n",
    "joblib.dump(ngram_vec_tfidf, '../BDS_project/ngram_vec_tfidf.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
